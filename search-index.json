[{"content":"A lot of people have been asking what I\u0026rsquo;ve been up to since I left Plaid at the beginning of this month. I was at Plaid for 4 years, which were amazing and I am very thankful for the amazing people I\u0026rsquo;ve met and work I\u0026rsquo;ve been able to do.\nI am not funemployed, and I don\u0026rsquo;t want to evoke concepts related to that. I\u0026rsquo;m grinding harder than I did while employed. It\u0026rsquo;s such a gift to be able to have software engineering skills that have been forged in a real tech company, and then let loose on personal projects. I\u0026rsquo;m working on learning as much as I can about the AI space and debating if I should make that my next 4-year move. AI has been moving faster and faster, and there are so many toy projects I want to build:\nAlready built this, but my Notion AI autotagger Deepfaking my own voice and using it to read ebooks out loud - hopefully deepfaking my own voice would bypass ethical constraints? Running LLMs on my own hardware A Biblical RAG Learning about the tradeoffs of RAGs in general, plus the cheapest arch to roll one out But I don\u0026rsquo;t want to just build toy projects. Specifically, I want to build an AI decompiler. I have done a little bit of work in the game decompilation space for Super Smash Bros. Melee, a video game that\u0026rsquo;s dear to my heart. If you want to know more about the general space, this doc that I\u0026rsquo;ve contributed to is a good place to get started. Last year when GPT-4 came out, I had a pretty strong feeling that LLMs would be great as a decompiler assistant, and I dreamt about having the time to investigate this more thoroughly.\nAfter some preliminary testing, it\u0026rsquo;s not amazing out-of-the-box. I got some decent results on the general model that get anywhere from 60% - 90% of the way there, but it seems that video game decompilation is both:\nvery specific to the compiler used, its flags, and just generally niche and probably not in the training data different from even normal decompilation, as video game decompilation is what we call \u0026ldquo;match decompilation\u0026rdquo; - I might write more about this in the future and its tradeoffs If the LLM approach doesn\u0026rsquo;t work, I\u0026rsquo;ll probably investigate some other spikes before washing my hands and writing a nice public postmortem, but yeah, this is what I\u0026rsquo;ve been spending my time on!\nI also spun up this site after I left my job, as Medium \u0026amp; Substack just weren\u0026rsquo;t cutting it for me.\n","date":"2024-09-23","id":0,"permalink":"/posts/what-i-have-been-up-to/","summary":"A lot of people have been asking what I\u0026rsquo;ve been up to since I left Plaid at the beginning of this month. I was at Plaid for 4 years, which were amazing and I am very thankful for the amazing people I\u0026rsquo;ve met and work I\u0026rsquo;ve been able to do.\nI am not funemployed, and I don\u0026rsquo;t want to evoke concepts related to that. I\u0026rsquo;m grinding harder than I did while employed. It\u0026rsquo;s such a gift to be able to have software engineering skills that have been forged in a real tech company, and then let loose on personal projects. I\u0026rsquo;m working on learning as much as I can about the AI space and debating if I should make that my next 4-year move. AI has been moving faster and faster, and there are so many toy projects I want to build:\n","tags":["tech"],"title":"What I'm up to"},{"content":"In my journey as a blogger, I’ve published posts across platforms like Medium, Substack, and other proprietary blogging stacks. When writing more and more technical stuff, I realized that some stacks were definitely better than others.\nWhen consuming other people\u0026rsquo;s blog posts, the first thing that stood out to me was aesthetics. You get an impression about the platform and the person simply by the details of how their text looks. Does their code have great, language-specific highlights? Do they use monospace + does their platform support it? How is the image formatting? What about the base color scheme?\nAs I worked with more platforms, I became frustrated with how my posts looked different on varying sites. The aesthetics were just too divergent, and I couldn\u0026rsquo;t exactly express what I was writing in my Notion. My brain also noticed that there was an inverse correlation with \u0026ldquo;how cracked someone was\u0026rdquo; and their propensity to using Substack or Medium. I realized that it was time for change.\nSo, when designing something / researching what\u0026rsquo;s out there, the first exercise is to list out your requirements:\nFeature-set that I want# I mostly listed out these nice-to-haves in a blogging platform:\nMarkdown-driven. The format that I actually draft posts in + how I research things are in markdown-driven platforms (like Obsidian!), so it would be nice for the posts to be very similar Arbitrary code highlighting. Ideally I would like to just support every language I write, but sometimes the project I\u0026rsquo;m going to do will be niche enough that that would be a high expectation. I\u0026rsquo;m going to write a post soon on decompiling PowerPC assembly, and I doubt there\u0026rsquo;s an out-of-the-box solution View count per article. I like to see how popular different posts are. I also often post my blogposts on other platforms such as Reddit + X, and it\u0026rsquo;s nice to know how much traffic comes from there vs. direct links. Categorization. I had separate blogs for writing about Christianity \u0026amp; tech. The problem with this approach was that I actually wanted to write about more than just those two, but I didn\u0026rsquo;t really have a place to do that. But Medium and Substack seemed like you were supposed to focus on one specific topic rather than just a personal blog. So I wanted to have a place where I could write anything, and then just let people filter by the topic they\u0026rsquo;re interested in. Some other topics I wanted to write about were cocktails, food, video games, and more! Minimal upkeep. If I have to host the thing, I\u0026rsquo;d like to not have to spend any time configuring the website \u0026amp; it should just work. Inline \\(\\LaTeX\\) support. Substack added block LaTeX support, which is nice, but wasn\u0026rsquo;t exactly what I was looking for. Notion has inline LaTeX support which flows really nicely and allows you to just use it as an extended vocabulary while writing a paragraph. Nested bullets. You\u0026rsquo;d be surprised that Medium doesn\u0026rsquo;t support nested bullets. I had to do this silly workaround, and it only works up to two levels. WTF??? My stack + how it addresses my requirements# After some investigation, I realized that there\u0026rsquo;s a whole plethora of solutions around markdown driven-blogs. I found hugo as well as a beautiful theme for it called gruvbox (which also happens to be the theme that I use for emacs!).\nhugo gruvbox Sometimes, when you first express your requirements and see what\u0026rsquo;s out there, you realize that people are beautiful and have often thought much more deeply about the problem you\u0026rsquo;re trying to solve than you could have ever imagined. Hugo often felt this way. They\u0026rsquo;ve done a great job expressing the problem of markdown files -\u0026gt; static site and have added all types of enhancements on top of markdown! It\u0026rsquo;s also very easy to add things like inline \\(LaTeX\\). The categorization problem I was talking about they\u0026rsquo;ve solved with taxonomies, which are honestly way more in-depth than what I needed; I can just solve my issue with using one of their default taxonomy, tags.\nI was able to address all of my feature requests easily with hugo with one exception: view count per-blog-post. I could integrate Google Analytics, but the numbers may be skewed by adblockers. I also wouldn’t know where readers came from. But does that really matter? What I truly value is the discussion sparked by my posts, not just the view count.\nThis stack however is not a one-size-fits-all recommendation for bloggers. I definitely pulled out my hair a bit figuring out how to configure hugo with the theme, and I don\u0026rsquo;t think using GitHub pages is viable for anyone who is non-technical. But, then again, most of the features I care about only matter to technical people \u0026ndash; Medium \u0026amp; Substack should be good for most other use cases.\n","date":"2024-09-14","id":1,"permalink":"/posts/blogging-platform/","summary":"In my journey as a blogger, I’ve published posts across platforms like Medium, Substack, and other proprietary blogging stacks. When writing more and more technical stuff, I realized that some stacks were definitely better than others.\nWhen consuming other people\u0026rsquo;s blog posts, the first thing that stood out to me was aesthetics. You get an impression about the platform and the person simply by the details of how their text looks. Does their code have great, language-specific highlights? Do they use monospace + does their platform support it? How is the image formatting? What about the base color scheme?\n","tags":["tech","meta"],"title":"Choosing a Blogging Platform: Aesthetic and Technical Considerations"},{"content":"Originally posted on Medium.\nI built the thing I talk about in this blog post — if you want to check it out, it’s here!\nNotion, like every tech company, has been shoving AI features down our throats for the last couple of months at the cost of customer UX. So I disabled them. You can do this yourself by just messaging support — I got the idea from this Reddit thread, which is one of many. Ever since I disabled it, the UX has at least returned-to-normal, and performance of editing has increased (have you ever noticed how Notion lags a bit every time you press SPC so that it can show you the AI toolbar?).\nAs I’m about to enter a brief phase of unemployment and grinding on personal projects, I’m looking for quick AI projects to whet my appetite to build. It turns out that some of Notion’s AI features were so simple that they’re great intro projects. Specifically, I was intrigued with building auto-labeling for my journal entries. Notion has a feature that, for a given database, you can label it with tags; on top of that, it has an AI feature that will read through all your entries and auto tag them:\nSo I’m already a paying customer for Notion. But they have the gall to charge me an additional $8/m to support this feature? Absolutely ridiculous! They already charge me $4/m simply to host my data and barely iterate on the product. To break this down on why this is ridiculous:\nThey already have margins from me paying to use Notion. Them adding these AI features on for free would be compelling customer-lock-in This feature can be implemented within a week by a disgruntled software engineer (me! it’s me!). Sure, I know, it’s not exactly the full scope of the things that feature offers (I’m guessing they have an async job kicked off when you make edits?), but it’s good enough for my purposes. In reality, using the API for GPT 4o is likely much cheaper than $8/m. Also, back when I had this feature on, they hadn’t even migrated to using the later GPT models. 🤮 The project# The idea behind this is a great use of AI! Especially for my journal, I want to have the barrier of entry to write a journal entry (hehe) as low as possible, and keeping up the effort to manually tag every entry is a pain.\nWith the release of OpenAI’s structured outputs that guarantee that it returns something within your schema (aka the tags that you want), it’s very easy to guarantee that the AI output is just a list of tags.\nAs of right now, I have 451 journal entries that go back all the way to 2016 (yes, the start of reflective Stephen). Roughly 90 of them were tagged. And due to my journal being mostly organic growth, sometimes the tags that I used changed over time, and so they weren’t a consistent way to search through my journal.\nDesign# I knew that I had to do the following:\nUsing the Notion API: Pull the content for all my journal entries Using the OpenAI API: Feed the content into 4o and ask it what it would label the entry Using the Notion API: Overwrite the entry’s tags with the new generated tags Since this involves a lot of phases and any one of them can fail, I separated the scripts’ running into four phases after learning the basics of the Notion API:\nGet all the pageIDs in the database (my journal) For each pageID, get the content Ask ChatGPT given the content \u0026amp; title \u0026amp; some more stuff what tag(s) the entry should have Actually write these tags to Notion …and then built in support for snapshotting after each phase ran. The python script saves all of the results locally using pickle, which is something that works great in dev, but would not recommend using in production (my friends have horror stories!).\nTo actually get OpenAI to tag my posts well, I had to experiment with prompting, which leads to our next section.\nPrompting# This project is the wake-up call I needed to discover how important prompting is. At first, I thought I could just copy and paste my journal entry into ChatGPT and hope for some good tags. I hoped wrong, here are some of the issues I ran into:\nobviously, i needed to make sure that the AI only returned tags. You can’t do this via the web interface the AI was pretty tag-happy and added tags at a whim, when I really didn’t think it should tag it with that there wasn’t a way to pass in additional context, such as “X is my brother.” First, we want to use the structured outputs feature from OpenAI to make sure it only returns tags, and we can use them in code. That was easy enough, but I had to learn how the schema format works.\nAfter that, I discovered that there is a level of knowledge required about my life that are not easy for the AI to understand just from my entries. For example, how is the AI supposed to know the name of my brother? Girlfriend? Church? What school I went to? I realized that I would have to give it more information than just the entry, and also would have to make sure that the additional context doesn’t bleed into its tagging decision (just because I talked about my brother in the context doesn’t mean that he’s in the journal entry). There are three things we can modify: the system prompt, the schema, and the user prompt. Normally, on https://chatgpt.com/, you can only modify the user prompt. So I ended up coming up with this solution.\nIn the system prompt (context for how the AI should behave):\nYou are an AI assistant that labels content with appropriate tags. Please analyze the given title and content and assign relevant tags from the provided list. Be conservative in your tag selection: - Only assign tags if there\u0026#39;s a medium to strong correlation with the title and content. - It\u0026#39;s better to assign fewer tags or even no tags than to assign irrelevant ones. - Consider the context and overall theme of the content, not just keyword matches. - If you\u0026#39;re unsure about a tag, it\u0026#39;s better to omit it. Additional context to help understand the entries: {additional_context} The additional_context variable is simply an envvar that has things like \u0026ldquo;x is my church\u0026rdquo;.\nThen, in the user prompt, I passed it the title, content, and a reminder to tag the entry and be cautious about tagging.\nFrom a high-level:\nsystem prompt:DirectivesAdditional Context user prompt:TitleContentSome directives additional fields:schema: [ENUM TAGS] — this makes sure that OpenAI uses your custom list of tags, and only returns those. Methodology# There’s been a lot of hype around Cursor, the AI-powered fork of VSCode. I’m a committed user of Emacs, but my integration with ChatGPT has been getting a little stale as gptel is pretty bare-bones (it is possible I have not been keeping up with its new features). I decided to try it out for this project and then later, attempt to fold in these UX features into Emacs.\nCursor is amazing. I barely wrote any code for this project myself. I often just selected the whole file, pressed CMD + K, and told it to add x feature.\nThis doesn’t mean non-technicals can build fully-fledged apps on their own with Cursor. I was very specific with my requirements, and I understood thoroughly how this project would work down to the checkpointing feature. I just didn’t want to take the time to learn Notion’s API. On top of that, OpenAI’s new structured output feature is brand-new, so there’s no way that Claude 3.5 Sonnet would have known about it.\nI also wrote a couple of scripts that helped debug this project as I ran it over and over. The most helpful script allows you to run all 4 phases on just one page within the database, so if you end up trying this project yourself, check out scripts.py.\nClosing thoughts# There are probably features that Notion could build that reasonably use their customer-lock-in. If they made a RAG on all of my workspace, that would be sick. Or if I could figure out all the things I’ve said about git! They could build an amazing search that also processes your attached images, and runs OCR on them, and/or uses location information to be like \u0026ldquo;what in my workspace is about Paris?\u0026rdquo; But I don\u0026rsquo;t have a lot of faith considering that their current search is abysmal, and I\u0026rsquo;ve just been disappointed time and time again with their roadmap.\nI’m kind of soft-evaluating Notion alternatives, but it’s been hard to figure out exactly what my requirements are. Offline mode is important, but also I want to be able to share my documents, I want them to look pretty, I want nice looking code blocks, I want features beyond basic markdown ones…. it’s hard to find all of these. Also, lowkey, it would be cool to have a platform for my blogs that isn’t Medium or Substack. My search continues…\nFor now, though, I’ll be using this tagger to help auto-tag my entries and rediscover my old entries all over again. It’s always funny to find an entry that’s titled “I can’t do this anymore” and see the tag Dating 😅. If you want to use this and are struggling with my GitHub, feel free to open an issue or write a comment here! Onto my next project :)\n","date":"2024-09-04","id":2,"permalink":"/posts/notion-ai/","summary":"Originally posted on Medium.\nI built the thing I talk about in this blog post — if you want to check it out, it’s here!\nNotion, like every tech company, has been shoving AI features down our throats for the last couple of months at the cost of customer UX. So I disabled them. You can do this yourself by just messaging support — I got the idea from this Reddit thread, which is one of many. Ever since I disabled it, the UX has at least returned-to-normal, and performance of editing has increased (have you ever noticed how Notion lags a bit every time you press SPC so that it can show you the AI toolbar?).\n","tags":["tech"],"title":"Why pay for Notion’s AI? I built my own auto-tagging tool in a week!"},{"content":"Originally posted on Substack.\nBrief doc I\u0026rsquo;m sending to my friendos\nFor transparency, I’m going to recommend a paid window switcher I use for Mac OS X called Contexts. It’s saved me so much time and has made using my computer a breeze; so much so, that I’ve bound it to CMD+Tab. I’ll attempt to justify this in the doc.\nThe default window management paradigm in Mac OS X, for me, left much to be desired. I grew up using Windows, which has a pretty different pattern for how you Alt+Tab between windows.\nIn Mac OS X, when you CMD+TAB, you can switch between apps; however, if you want to specify within windows of the same app, you’ll have to issue another command: `CMD+`` lets you switch between windows of the same app. So you often have to issue multiple commands to get to the right window, which doesn’t even address that you often have to cycle a lot to get the app that you’re looking for.\nAs I’m a huge proponent of operating my computer with my keyboard as much as possible, you can get to the right “app” at least by using spotlight instead of CMD+Tab. You do CMD+SPC which pulls up Spotlight, and then you type in “Chrome” or “Chr” and then press enter. This solves the scrolling problem for CMD+Tab. However, we still have the issue of getting the right window focused.\nI personally prefer the Windows paradigm of treating every window as unique, rather than grouping them by app. So, after investigating a bit, I found an app that does exactly that!\nEnter Contexts# https://contexts.co/\nContexts doesn’t just disambiguate between different windows of the same app, but it also lets you search for the window with a prefix of its title. So I can type in Hold(CMD+TAB)+Sla and I’ll get Slack really quickly. Faster than I could scroll to it.\nAlso, if you have two chrome windows with one with calendar and the other with some other pages, you can just type in Cal into the window and it’ll pull up.\nIt has a free trial! Try it out 🙂.\n","date":"2024-03-22","id":3,"permalink":"/posts/window-management/","summary":"Originally posted on Substack.\nBrief doc I\u0026rsquo;m sending to my friendos\nFor transparency, I’m going to recommend a paid window switcher I use for Mac OS X called Contexts. It’s saved me so much time and has made using my computer a breeze; so much so, that I’ve bound it to CMD+Tab. I’ll attempt to justify this in the doc.\nThe default window management paradigm in Mac OS X, for me, left much to be desired. I grew up using Windows, which has a pretty different pattern for how you Alt+Tab between windows.\n","tags":["tech"],"title":"How I do window management in Mac OS X"},{"content":"Originally posted on Substack.\nTry it out here if you like pressing buttons as much as I do! GitHub if you like reading code.\nDuring the holidays, I wanted to get better at answering questions like “what is 7 half steps up from A?1” I often found myself in the situation of having these problems as a lot of guitar chord sheets are written something like “A capo 7” which means you put the big barre thing on your guitar and play an A-shape chord. When using a capo, the actual underlying chord is \u0026lsquo;A + 7 half steps\u0026rsquo;. This means if you\u0026rsquo;re collaborating with another instrument or with someone not using a capo, you need to communicate the actual chord you\u0026rsquo;re playing. This requires some mental math, which I found slightly embarrassing as I didn\u0026rsquo;t always immediately know what chord I was playing.\nI had an idea that if I had a program ask me a ton of these questions, my brain would develop some type of internal algorithm to answer the question. And… spoiler alert, it did! Though we’ll talk about that later.\nWhat / how to build?# Making a program that calculates intervals and randomly picks notes isn’t that difficult. However, I did make a couple of decisions on how to build the app based on some goals + non-goals:\nGoals# To be able to use the app both on my computer and phone. Phone mostly because I’d use it at the gym. Fast iteration speed plus once I was done to put a bow on it. I have a lotof personal projects that are just in semi-limbo and I was tired of notfinishing things. Look ok to nice Non-goal: storing state. Didn’t have a lot of upside for the upfront + maintenance complexity These goals pushed me heavily into making some type of web app despite my disdain for JavaScript. I also limited the feature set to a simple quiz, which asks you to identify the next note based on a random note and half-step interval.\nSince I wanted to really go fast, I didn’t want to spend time struggling with TypeScript compilation errors. My stack ended up looking like this:\nJavascript x React with create-react-app Deploying via Vercel No backend I focused first on building the underlying interval calculation, which I overly complicated for myself as I focused on enharmonics too early. For those who don’t know, enharmonics are different ways of writing the same note (e.g. A♯/B♭)2. After maybe an hour, I had a program that looked like this and worked:\nEnter ChatGPT# I\u0026rsquo;m not a fan of CSS, and even though it has improved over time, I never took an interest in mastering it. So as GPT4 now accepts images, I was like “why not just ask it to make it look better?”\nPrompting is usually a bit of a magic art, but in this case, I was pretty straightforward:\nand after a couple of corrections, and some screenshots of bugs it had introduced, I had this!\nIt was so much better than something I would have come up with by myself. And once I had this screen presented to me, I had a couple of straightforward suggestions which then made the final product. Also, making the app look nice and adding visual feedback to correct \u0026amp; incorrect answers made me a lot more motivated to play the game, which was great.\nI basically made it so that CSS was 100% ChatGPT’s arena, and the React components were “allowed to be refactored”; the core logic I did not allow ChatGPT to modify. I’m glad I kept this abstraction barrier, as ChatGPT often removed features or introduced slight logic bugs when I allowed it to just rewrite the components. Some examples:\nIt nuked the feature I wrote in to message what the correct note should have been if you get it wrong It didn’t notice my bug and sometimes made it worse that displayed different enharmonics on rerenders, since it depends on Math.random() It would highlight the right answer on errors, but then fail to do that on successes which was confusing 💡 There’s always a disparity between expressing the problem statement in language → actually solving the problem. The gap between precisely expressing the problem and solving the note interval solver was super small for me; however, for expressing how the app should look + how to implement it in CSS, I was mostly at an impasse and only had vague sketches in my head. ChatGPT’s raw velocity was absolutely insane for me.\nHow my brain got better at this# I’ve only spent maybe like 30 minutes actually using the tool, but I’ve already gotten so much better at the problem! Let’s go back to the original problem of “7 half steps up from A.” How my brain solves it is:\nConverts 7 half steps → perfect 5th up Imagines a violin and goes up a string, and sees E Unfortunately (2) is pretty specific for me, as I’ve played violin since I was 8 or 9. But you can re-arrange this to:\nConvert half steps to a music interval, like “minor 6th” Go from interval to note Which is pretty reasonable. Also, (2) is pretty valuable in itself as a musical skill 😊.\nConclusion# I’ve been programming for a while. One thing they don’t tell you in school is that when you get better at making personal projects + fast iteration, you get better at solving your own (technical) problems. Sure, your first personal project might not be worth it on the “effort invested vs. time saved” curve; however, if you get really good at making programs that solve your problems, you’ll start to find that it swings really far in the other direction.\n…of course, writing this article definitely took more of my time but 🤷‍♂️. I also kind of enjoy doing this type of thing so it’s still worth it for me.\nWe are also in such a golden age of creating really fast apps and deploying them as tooling is so good. Like I legit just launched a website with my app on it for free. Go Vercel!\nit’s E\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nyes I know that these are different notes depending on if a temperament is assumed. this is another reason why I cut scope and didn’t do music intervals and just stuck to half steps.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2023-12-27","id":4,"permalink":"/posts/half-steps/","summary":"Originally posted on Substack.\nTry it out here if you like pressing buttons as much as I do! GitHub if you like reading code.\nDuring the holidays, I wanted to get better at answering questions like “what is 7 half steps up from A?1” I often found myself in the situation of having these problems as a lot of guitar chord sheets are written something like “A capo 7” which means you put the big barre thing on your guitar and play an A-shape chord. When using a capo, the actual underlying chord is \u0026lsquo;A + 7 half steps\u0026rsquo;. This means if you\u0026rsquo;re collaborating with another instrument or with someone not using a capo, you need to communicate the actual chord you\u0026rsquo;re playing. This requires some mental math, which I found slightly embarrassing as I didn\u0026rsquo;t always immediately know what chord I was playing.\n","tags":["tech","music"],"title":"I made a web app to get better at adding half-steps to notes"},{"content":"Originally posted on Substack\nYou know the first verse of the Bible, right?\nIn the beginning, God created the heavens and the earth.\nGen 1:1 NET\nThe word for God here is Elohim. There are some interesting tidbits about this:\nThe noun is in its plural form. Singular would be Eloah. While this seems really controversial, in most of the usages, it’s paired with a singular verb. AKA “created” up there is masculine singular. So it’s often interpreted as a majestic plural.\nAlso, the word is kind of impersonal. We often use the word to describe other gods in the bible.\nYou shall have no other gods before me\nExo 20:3 ESV\nIn that verse, the word is also elohim, and is often translated as lower capitals to indicate it’s not talking about the Jewish God.\nHowever, something fascinating is that Genesis isn’t consistent with what term it uses for God. Not just in the whole book, but literally by chapter 2. In chapter 2, the writer(s) start using Yahweh Elohim instead of Elohim. My translation notes this difference by writing it as “LORD God” instead of just “God” or “Lord”:\n…when the LORD God made the earth and heavens.\nGen 2:4 NET\nYou can actually pretty easily spot the difference if you check out the Hebrew. Yahweh Elohim looks like this: יהוה אלהים, whereas Elohim looks like this: אלהים. A reminder that Hebrew is right-to-left 🙂. So the difference between these two is just the presence of the tetragrammaton / the personal name of God (Yahweh).\nIsn’t that odd? That God changes names within two chapters? Or that it kind of zooms in on specificity in Genesis 2? Another thing that’s odd is that God hasn’t actually revealed his name to the readers / Jewish people yet in the story. Rather, the Jewish people don’t even exist, as it’s the creation narrative. God reveals his name, Yahweh, in Exodus 3:15, as well as a brief etymology in 3:14.\nMy thoughts are that this is pretty strong evidence that Genesis 2 is a different creation account + has a different author, possibly writing later in time, as this seems to be an anachronism. Another way to think of this is that Genesis 1 and Genesis 2 serve different purposes.\nStill forming opinions and thoughts, but this is a pretty interesting find for me.\n","date":"2023-10-10","id":5,"permalink":"/posts/the-first-use-of-yhwh-in-the-bible/","summary":"Originally posted on Substack\nYou know the first verse of the Bible, right?\nIn the beginning, God created the heavens and the earth.\nGen 1:1 NET\nThe word for God here is Elohim. There are some interesting tidbits about this:\nThe noun is in its plural form. Singular would be Eloah. While this seems really controversial, in most of the usages, it’s paired with a singular verb. AKA “created” up there is masculine singular. So it’s often interpreted as a majestic plural.\n","tags":["christianity"],"title":"The first use of YHWH in the Bible is pretty odd"},{"content":"Originally posted on Substack\nI’ve often encountered Christians that believe the world was created in 7 24-hour days, because “that’s what the Bible says” in Genesis 1 and they won’t believe otherwise.\nThere are a ton of arguments against this “fact,” but I think the most compelling one is the linguistic ambiguity for the word “day” (yom) used in the creation account. First, let’s take a look at an English translation for one of the days of creation:\n\u0026ldquo;God called the light Day (yom), and the darkness he called Night. And there was evening and there was morning, the first day (yom).\u0026rdquo;\nESV Genesis 1:5\nThe Ancient Hebrew word used here “yom” יוֹם, can mean the following things based on its entry on Wikipedia:\nPoint of time (a specific day) time period of a whole or half a day: Period of light (as contrasted with the period of darkness), Sunrise to sunset Sunset to next sunset General term for time ( as in \u0026lsquo;days of our lives\u0026rsquo;) A year \u0026ldquo;lived a lot of days\u0026rdquo; Time period of unspecified length. \u0026ldquo;days and days\u0026rdquo; Now, if you were brought up in the education system, you probably know that Wikipedia isn’t a valid academic source 😛. However, it does seem to indicate that something interesting is going on here as the word can mean drastically different time extents based on the context. One way to learn a bit more is to compare other usages of the word yom in Genesis (the word is used throughout the Hebrew Bible — I thought it’d be best to focus just on Genesis as we can assume it was edited as one writing piece).\nNote that yamim is the plural of yom for the following examples, as there aren’t actually a lot of usages of the singular form beyond the creation account.\n“In the course of time (yamim) Cain brought to the LORD an offering of the fruit of the ground”\nESV Genesis 4:3\nThis is the loosest translation of yom I could find in Genesis. The way the ESV has rendered it looks pretty similar to the English phrase “In these days…” which is also very non-specific when it comes to extent.\n“Now Abraham and Sarah were old, advanced in years (yamim). The way of women had ceased to be with Sarah”\nESV Genesis 18:11\nYears?! What?! I guess you could say “advanced in days.”\nAnd God said, “Let there be lights in the expanse of the heavens to separate the day (yom) from the night. And let them be for signs and for seasons, and for days (yamim) and years\nESV Genesis 1:14\nSimilar to Genesis 1:5 where the word is used both to describe daytime as well as specific time extents. This is most likely a literal day, as the words used for “seasons” and “years” are more specific as well.\nThese are the generations of the heavens and the earth when they were created, in the day (yom) that the Lord God made the earth and the heavens.\nESV Genesis 2:4\nThis one is a bit trickier for me. The verse is right before the creation of humanity in Genesis 2 (which happens during the events of Genesis 1). In MSG and NLT, the word “day” doesn’t even show up, nor does any extent of time. As this prefaces the writer(s) zooming into humanity’s creation, it could be referring to the specific day that happens on, but my pretty uneducated guess is that it’s an extent of time that refers to the whole creation timeline, kind of serving as a capstone of the creation account.\nUltimately, the word is ambiguous. Readers often come into Genesis with their preconceived notions of what it should say and how the world was created and then attempt to make an interpretation of this thousands-of-years-old text. Instead of fully pushing this argument into a dichotomy, I want to make the following point: it’s ok to not know what’s going on in the creation account for sure. It’s also really hard to get into the writers’ headspace and really think: what were they trying to say through Genesis 1? What did they care about? Maybe nailing down that days were slightly less than 24 hours or the commonality of carbon throughout the universe weren’t exactly top thoughts?\nI think it’s short-sighted to make strong claims about what precisely the Hebrew Bible says without even attempting to investigate the original language, so go for it! I used a free tool called Logos to look up the Hebrew inline \u0026amp; compare different translations. Don’t blindly believe what you hear: check it! Also this post isn’t intended to completely discredit the creation of the world in 7 literal days. In a worldview where God exists and is omnipotent, anything can be accomplished, even if it’s manufacturing evidence that the world was created over a much longer span of time. But yes, your call on what side of the argument you’re on. Cheers!\n","date":"2023-06-14","id":6,"permalink":"/posts/yom-examining-creations-timeframe-with-linguistics/","summary":"Originally posted on Substack\nI’ve often encountered Christians that believe the world was created in 7 24-hour days, because “that’s what the Bible says” in Genesis 1 and they won’t believe otherwise.\nThere are a ton of arguments against this “fact,” but I think the most compelling one is the linguistic ambiguity for the word “day” (yom) used in the creation account. First, let’s take a look at an English translation for one of the days of creation:\n","tags":["Christianity"],"title":"Yom: Examining Creations Timeframe With Linguistics"},{"content":"Originally posted on Substack\nedit: this blogpost was initially wrong when I published it. Thanks to some comments I got, I learned I didn’t fully understand TrueTime or Spanner — I’ve spent some time learning and understanding the core concept again, and have updated this artifact. This is an externalized resource for me that I hope can be helpful for others.\nWhen I was reading the famous paper on Spanner, Google’s globally distributed linearizable database, I really struggled with the concept of TrueTime, which is a core component of why they were able to get their guarantees. After trying to wrap my head around it, I created the following artifact (IMO, TrueTime deserves a mini-ish paper or post on its own):\nSo first, let\u0026rsquo;s assume that we have a way to globally agree in a distributed fashion on a single value (this is Paxos, which I won\u0026rsquo;t be going into here). In this case, we want that value that all nodes to agree on to be the correct ordering of transactions. However, even with such a powerful primitive, if we were to just use normal timestamps, we’ll still have issues actually assigning an order to transactions.\nClocks are always inaccurate. Not just a set amount from the current time — they unfortunately also drift. And in different amounts from each other. So in distributed systems, clock synchronization is a hard problem, and generating timestamps that are ordered globally is nontrivial.\nImagine you wanted to globally order transactions by what time they committed. If a clock was off even between two nodes, we already are SOL if we use the local time as the ordering constraint:\nSo given nodes A and B with TXNs, and given \\(T_A, T_B| T_A \u003c T_B\\), where \\(T_A\\) and \\(T_B\\) are transactions on nodes A and B, and the \u0026lt; sign indicates that “transaction A precedes transaction B,” if we were to attempt to globally order the TXNs based on reported timestamp, we’d conclude that \\(T_B \u003c T_A\\).\nThis breaks causality. Imagine \\(T_B\\) depended on \\(T_A\\); e.g. \\(T_B\\) was a message reply to \\(T_A\\). So even if we were to have global agreement on the ordering of transactions, if we use the local timestamps that node A and B generate, the ordering will be incorrect.\nClocks aren’t just slightly inaccurate. They’re like 100s of milliseconds inaccurate, which can lead to large windows where causality will be broken.\nSo imagine we were able to somehow guarantee that all the clocks are \\(\\pm\\) 3.5ms of the actual time. So all clocks in the system are 7ms of each other (we’ll call this e. Google actually has this guarantee with the use of GPS + atomic clocks).\nGiven this, we can actually generate a total ordering even with clocks that are off. First, instead of storing just one number as the timestamp for a transaction, every transaction has a [start, end] bound. end - start = e, and the actual timestamp \u0026amp; the local timestamp are both within the range. Let’s revisit our previous example, but now with time intervals:\nSo as before, if we were to rely on the “reported time,” we would come to the wrong conclusion that \\(T_B\\) happened before \\(T_A\\). Here’s a simple fix though now that we have intervals: in the case where we have a conflicting transaction with overlapping intervals, make it so that the one with the later start time waits until it’s no longer overlapping. Concretely, make \\(T_B\\) wait until it’s interval has at least a start of 2. If we were to do this, then there’s no way \\(T_A\\) and \\(T_B\\) can have incorrect ordering.\nThe key takeaway is that since we have the intervals, we have a bound on how long to wait until there’s no longer a conflict. Before, we couldn’t be sure with just the local timestamps that there was a problem, as we didn’t have a bound on the timestamps’ uncertainty.\nBrief thoughts on Spanner# I’ve handwaved some of the finer details on how TrueTime is used in Spanner to keep the scope of this blogpost small. However, technically the scheme I described should be correct to generate a total ordering.\nWhile Google went about creating a globally distributed serializable database like this, there haven’t been many follow-ups that build off of this from my knowledge. This could be for a lot of reasons that I’m definitely not an authority on, but some ideas:\nDevelopers are ok with dealing with eventual consistency Google’s implementation of Spanner is too expensive …or the people who want the guarantees are just using the GCP version The players who deal with scaling problems like this already have their own solutions, public or not. Regardless, it was fun to learn about this and hopefully this was helpful 🙂\nAppendix# Why are the reported times not at the center of the TrueTime intervals?\nI’m not entirely sure about this, but (1) the API doesn’t actually specify where the reported time is — just that it’s an interval. I’m guessing it’s possible for the local time to drift within the interval and it depends on factors like network synchronization and the tendency of the local clock to drift.\n","date":"2023-06-04","id":7,"permalink":"/posts/spanner/","summary":"Originally posted on Substack\nedit: this blogpost was initially wrong when I published it. Thanks to some comments I got, I learned I didn’t fully understand TrueTime or Spanner — I’ve spent some time learning and understanding the core concept again, and have updated this artifact. This is an externalized resource for me that I hope can be helpful for others.\nWhen I was reading the famous paper on Spanner, Google’s globally distributed linearizable database, I really struggled with the concept of TrueTime, which is a core component of why they were able to get their guarantees. After trying to wrap my head around it, I created the following artifact (IMO, TrueTime deserves a mini-ish paper or post on its own):\n","tags":["tech"],"title":"My Notes on Google's TrueTime"},{"content":"Originally posted on Medium.\nthey really do. I have most of them turned off on my phone.\nfirst, idk who to blame about these, but there is this class of notifications that are like\n“feeling hungry? order UberEats now!!”\nsomeone gave someone this lever to pull to increase engagement. the first someone upsets me, and i sometimes think about the other someone and also get angry.\ni turn all of these off, when I can actually turn them off. in the case where an app doesn’t let me disable them, I turn off all notifications for that app. they’ve lost my trust.\nonce you start turning these off, you realize that most notifications are actually just avenues for companies trying to boost your engagement with their apps. like those reddit notifications you get about random people posting? totally for engagement. do you actually need to hear from them? no! turn them off. give me my autonomy: i’d rather pull than be pushed.\nalso i wish I could cancel badges. i turned them all off, because WHY. there’s something in my brain that makes me want to clear them. maybe i have a problem. idk. I can’t disable the settings app badge though so that’s bothering me right now but don’t worry we have more to talk about\nmessaging notifications# ok, so once we’ve cut these out, we now have what I call “messaging notifications.” these are actually things I care about. like my friends reaching out to me!\nhowever, i turn these off sometimes too via Do Not Disturb. often people reaching out to me can really take me away from my present or ruin my focus. imagine you’re having dinner with someone but you keep reading messages from other people or messaging them — isn’t that really sad? you literally have someone of infinite depth right in front of you! talk to them!\nbut also, there are some notifications that are really mentally heavy, and could completely ruin your day. i’ve definitely gotten some of these messages. if possible, i’d like to handle these things when i’m not working or having a good time with friends, since it’ll just change my reality. you know, there used to be times when people weren’t reachable 24/7. maybe there was some implicit wisdom to that (can’t be explicit because people back then probably had no idea we’d be where we are now).\nwork# ah yes. work. work notifications. these are a mess. i actually always have them disabled, but when I need to be around to respond to things (like support oncall), i dedicate 1/3 monitors to a fullscreen slack. idk if that’s a good idea. it has its pros and cons. try it out (well if you have a screen to spare).\nsome people really do be slacking all day. like, you know, using the slack app. not me; I find that most of my work is creative or like churning something out. don’t need to talk to someone to do that!\nconc# not sure if this helps anyone out there, but i’ve just been so DONE with notifications as a concept. i hope you can claim some of your autonomy back. ❤\nstephen\nfurther reading# https://www.reddit.com/r/ProgrammerHumor/comments/60wx3z/this_is_why_you_shouldnt_interrupt_a_programmer/ trigger-action planning ","date":"2023-06-02","id":8,"permalink":"/posts/notifs-suck/","summary":"Originally posted on Medium.\nthey really do. I have most of them turned off on my phone.\nfirst, idk who to blame about these, but there is this class of notifications that are like\n“feeling hungry? order UberEats now!!”\nsomeone gave someone this lever to pull to increase engagement. the first someone upsets me, and i sometimes think about the other someone and also get angry.\ni turn all of these off, when I can actually turn them off. in the case where an app doesn’t let me disable them, I turn off all notifications for that app. they’ve lost my trust.\n","tags":["tech"],"title":"Notifications Suck"},{"content":"Originally posted on Medium.\nI use git a ton in work and my personal life, and have come up with a couple of aliases that have made using it so much more pleasant and fast. First, I’ve renamed git to g. You have no idea how much typing that’s saved me (I also don’t know).\nalias g=\u0026#34;git\u0026#34; Aliases# git allows you to alias commands. In the spirit of renaming commands to one character, here are my favorite aliases:\n[alias] d = diff --color s = status p = push c = checkout a = add cm = commit -m pl = pull cl = clone r = rebase b = branch These are all in my ~/.gitconfig file. So when you navigate into a folder for the first time and want to type git status, that translates to g s. Look how short that is! Or writing a commit would be g cm 'commit'. Wow!!\nYou can also set aliases from the git CLI which will modify the .gitconfig:\ngit config --global alias.c \u0026#39;checkout\u0026#39; Some other functions# add-commit-push: I often push a ton of commits to my branches, as my organization (and projects) usually squash PRs. So I made a function to do this in one command:\nfunction acp { g a -u \u0026amp;\u0026amp; g cm $1 \u0026amp;\u0026amp; g p } This function:\nadds all tracked files (so doesn’t add new files) commits with the message that you pass in pushes So the usage goes something like acp 'commit'.\ngit-merge-master: I also often need to merge in the commits from master, usually to unbreak CI 😞. I don’t use rebases often as when you create PRs, rebases can mess up the comments once you force push. So here’s my command for gmm:\nalias gmm=\u0026#34;g c master \u0026amp;\u0026amp; g pl \u0026amp;\u0026amp; g c - \u0026amp;\u0026amp; g merge master --commit --no-edit\u0026#34; ZSH branch name# Now that MacOS X’s default terminal is zsh by default, more people are using zsh over bash. If you’re like me, you probably picked one of the many pretty themes (I picked agnoster) that also had the nice functionality of telling you a) if you’re in a git repository and b) what branch you’re on. This is super great as you don’t need to do a git status every time you enter a git repository.\nHowever. The way most of these themes implement this feature is by doing a git status every single time the prompt comes up. Which means most likely every time you press enter. I specifically had a repo that took a really long time to run git status; on the order of \u0026gt; 2 seconds. That means that every time I pressed enter, I had to wait for 2 seconds for the prompt to reappear.\nAs someone who takes latency really seriously and believes that slow systems infect your mind with slothfulness, this was unacceptable. Also, intuitively it didn’t make sense that to fetch just the branch name and the fact that it’s a git repository was so slow. It was most likely because git status also checks all of the statuses of changed files, which isn’t as important information for the shell prompt.\nSo I ended up finding this StackOverflow thread on getting just the branch name into the RPROMPT. However, I don’t really like using RPROMPT as it messes up your copy-pastes in the case where you want to copy both your command and your output. So I adapted it a bit to modify my PROMPT instead and disabled ZSH themes. It looks something like this:\nGeneral tips# In bash, — is an alias for “the last directory you were in.” So if you want to checkout to the last branch you were on, g c -. Or in normal git commands, git checkout -. I don’t like the normal diff tool used by git. Often for PR reviews, I’ll use difftastic to compare their branch to master (you do git diff master... to diff with the last common commit, which is what GitHub spits out in its interface). To overwrite what diff tool git uses, you’ll want to add this to your .gitconfig: [diff] tool = difft If you end up having a bunch of untracked files in your git repository by accident, you can nuke all of them by running git clean -fd. This is a dangerous command. Only do it if you’re ok with losing all of these files. Unsure if you can recover them via g reflog. Good job making it this far. Hopefully this helps out someone out there! I’m proud of most of my workflow optimizations, but I’m also totally looking for MORE. hmu if you have any cool tips or tricks for git, or anything really. Also I’ll probably write more of these, but since a lot of them come from just using Emacs, I might have to make it Emacs-specific going forward.\n","date":"2022-12-25","id":9,"permalink":"/posts/some-quick-zsh/","summary":"Originally posted on Medium.\nI use git a ton in work and my personal life, and have come up with a couple of aliases that have made using it so much more pleasant and fast. First, I’ve renamed git to g. You have no idea how much typing that’s saved me (I also don’t know).\nalias g=\u0026#34;git\u0026#34; Aliases# git allows you to alias commands. In the spirit of renaming commands to one character, here are my favorite aliases:\n","tags":["tech"],"title":"Some quick git (and zsh) workflow optimizations"},{"content":"Originally posted on Medium.\nWhy do we need AI to write blog posts? There’s been a trend of these AI tools to write things for you:\nhttps://www.notion.so/product/ai https://www.copy.ai/bloggers https://www.jasper.ai/examples/blog-posts Imagine you have something to say to people. So you come up with some representation of that thing you want to say; maybe bullet points, maybe a rant, maybe even some markdown stuck in a GitHub repository. Why can’t you just publish that?\nit’s probably more concise. AIs seem to expand things in an unpredictable fashion it’s your voice! speak loud! don’t hide behind some jank code. Some “benefits”:# SEO\nJasper advertises writing posts that’ll have better SEO Really short posts will be harder to find, and there’s been a trend of making medium-sized articles even when the content amount is low for ranking. Just look at recipes on Google 😕 I think SEO has messed up content in the last decade. Misc\nThere’s a reason people don’t just publish their diaries or journals online all the time. Writing publicly requires you to adapt your mental models so that other people besides yourself can understand. Maybe AI can do this? Maybe not? 🤷 CopyAI: You can “focus on the things you love” and free up your time from writing posts. OK, if you don’t love writing, why are you doing it? Maybe the act of creating an artifact about the thing you love can become a thing you love? Either way, I wrote this by hand in Notion. I also drew the above graphic on my iPad — here’s what OpenAI spit out for memes:\nPrompt: a stick figure diagram of a person talking to a robot, which is trying to talk to a group of people. however, the robot can’t talk, and instead the person has to shout around the robot I probably won’t be entertaining AI writing my writings anytime soon. This is the exact type of post I like: has a strong opinion, concise, and potential for discourse. LMK if there are reasons this could be a good thing. Keep it real homies\n","date":"2022-12-03","id":10,"permalink":"/posts/im-against-ai-blog/","summary":"Originally posted on Medium.\nWhy do we need AI to write blog posts? There’s been a trend of these AI tools to write things for you:\nhttps://www.notion.so/product/ai https://www.copy.ai/bloggers https://www.jasper.ai/examples/blog-posts Imagine you have something to say to people. So you come up with some representation of that thing you want to say; maybe bullet points, maybe a rant, maybe even some markdown stuck in a GitHub repository. Why can’t you just publish that?\n","tags":["tech"],"title":"I’m against AIs writing blog posts"},{"content":"Originally posted on Medium.\nPlease. It’s an insult to my brain. Like, you put the button in one place, and then you’re like “nah, let’s move it somewhere else.” Here are some examples that have annoyed me the most lately:\nLyft Bike Scan Button# This one sucks as I’m often opening the Lyft app just to ride bikes. So I immediately hit the bike button and I’m trying to hit the “Scan” button as quickly as possible. But no! Depending on how fast my internet is at the current moment, that banner will appear and push the Scan button up, which means I end up hitting the banner instead 😟; this is often a really frustrating start to my daily commute.\nNotion search results# ignore the page titles for your own sanity\nI use Notion as a power user at this point. When I’m trying to navigate to a page, I’ll press CMD+K to open the doc finder, and then type in some prefix of what I’m looking for. To pick a result, I’ll be using CTRL+P or N to go up and down, and often press enter in under a second. What’s crazy about this is it first returns one set of results, and then a pretty different set of results. IIRC rarely even the first result will change 😕.\nWhy it happens# Some ideas:\nLoading something and inserting it in a way that moves around other elements More complicated queries that would reorder the results. e.g. it appears the Notion search first returns title searches, and then actually searches the contents of documents which ends up in result reordering. What I call “UX fragmentation”. When personas of users differ so much or there are so many experiments running, that engineers and designers aren’t fully aware of what end-users are seeing. You’ve probably seen this with features being A/B tested. Sometimes, things are loaded in one order or another order depending on a plethora of variables. And also the timing of network responses. Do better# When you make a change to the screen, why not just commit to where it should be? Do the users and the metrics get benefit from “pseudo-responsiveness”? If the answer is yes just to the latter, I think it’d be fair to deem this a capitalistic-UX-anti-pattern. Get it out.\nIf anyone’s put thought into this or is annoyed by this, please lmk or send me resources and further readings so I can get more annoyed. Thanks:)\n","date":"2022-11-25","id":11,"permalink":"/posts/frontend-devs-stop-moving/","summary":"Originally posted on Medium.\nPlease. It’s an insult to my brain. Like, you put the button in one place, and then you’re like “nah, let’s move it somewhere else.” Here are some examples that have annoyed me the most lately:\nLyft Bike Scan Button# This one sucks as I’m often opening the Lyft app just to ride bikes. So I immediately hit the bike button and I’m trying to hit the “Scan” button as quickly as possible. But no! Depending on how fast my internet is at the current moment, that banner will appear and push the Scan button up, which means I end up hitting the banner instead 😟; this is often a really frustrating start to my daily commute.\n","tags":["tech"],"title":"Frontend developers: stop moving things that I’m about to click on"},{"content":"Originally posted on LinkedIn as a meme.\ni’ve been thinking about the big rocks every day\nfor those who don’t know: https://lnkd.in/gZGfgBE9\njust the other day, i was at whole foods. and i tried to fit the items into my cute tote bag haphazardly. they didn’t fit!!\nbut then, i put the straus whole fat milk first. and then the yogurt. and then i put the cheese, and the cute lil snax. i fit everything! the bag was kinda heavy though.\nthink about your big rocks🪨🪨🪨🪨\n","date":"2022-11-23","id":12,"permalink":"/posts/big-rocks/","summary":"Originally posted on LinkedIn as a meme.\ni’ve been thinking about the big rocks every day\nfor those who don’t know: https://lnkd.in/gZGfgBE9\njust the other day, i was at whole foods. and i tried to fit the items into my cute tote bag haphazardly. they didn’t fit!!\nbut then, i put the straus whole fat milk first. and then the yogurt. and then i put the cheese, and the cute lil snax. i fit everything! the bag was kinda heavy though.\n","tags":[],"title":"Big Rocks"},{"content":"Originally posted on LinkedIn as a meme.\nmy friends are all attachment styles this and attachment styles that when it comes to dating. however, has anyone had the brilliant idea of applying attachment styles to working at a tech company? I didn’t think so! now you might be thinking, “hey Stephen isn’t this a bad idea?” and yes, it is. but just like we should all hope to be secure partners in our relationships, we should also possibly strive to be secure capitalistic partners at work.\nfirst, what are attachment styles? from my very topical reading and a lot of projection, here’s a short summary as well as some relevant spotify songs. there are three styles: anxious, avoidant, and secure. anxious people (”inside out”, “used to you”) are often overinvested to the point of destruction in their relationships, constantly misperceiving slight signals as catastrophes. avoidant people (”Let’s Fall In Love…”) create distance from their partners when their intimacy lines start getting crossed. secure people are great. go read the book “Attached” if you’d like more information or potential trauma\ni think the following section is best suited as a list. NOTE that me listing them here isn’t me condemning these behaviors as I totally do them all the time. but maybe there’s something to think about 🤔. here are some avoidant traits at work:\nsetting your slack status to offline or away all the time large “DO NOT BOOK” blocks on your calendar restricting personal interaction / not attending social events at your company copying and pasting in your responses from another app so that people can’t see you typing not having a slack profile picture with your face in it refusing to read your email turning off notifications and only triaging if things are escalated skipping all hands reading a message and pretending not to read it …or marking it as unread so you can deal with it later, but then accidentally reading it and then never triaging writing in lowercase in a lot of these cases, these are defense mechanisms employed to make good use of your time. though it’s still useful to reflect on them instead of just doing them automatically.\nand anxious:\nbeing in multiple meetings at the same time so you don’t miss anything pressing enter too many times and sending tons of messages. and getting anxious when people don’t reply instantly stream of consciousness style typing replying instantly “why is your status away” double posting in the #social channel “why is no one reacting to my message” creating PRs for attention saying yes to everything so that your coworkers will like you long pairing sessions to get social contact …at this point i’m just recounting my own habits secure: honestly i have no idea that would be nice.\ni pride myself at being anxious-avoidant at work, the worst of the lot. have fun misclassifying yourself and your coworkers!\n","date":"2022-09-17","id":13,"permalink":"/posts/attachment-styles-at-work/","summary":"Originally posted on LinkedIn as a meme.\nmy friends are all attachment styles this and attachment styles that when it comes to dating. however, has anyone had the brilliant idea of applying attachment styles to working at a tech company? I didn’t think so! now you might be thinking, “hey Stephen isn’t this a bad idea?” and yes, it is. but just like we should all hope to be secure partners in our relationships, we should also possibly strive to be secure capitalistic partners at work.\n","tags":["tech","dating"],"title":"Attachment Styles at Work"},{"content":"Originally posted on the Plaid Engineering Blog while I was part of Plaid\u0026rsquo;s Developer Experience Team.\nThe developer experience team focuses on building tools and features that make it as easy as possible for developers to explore our APIs and integrate with Plaid. This year, our team adopted an OpenAPI schema (OAS) as a specification for our API. We launched this schema in beta earlier this year.\nOur team is responsible for maintaining three sources of truth for our API that allow developers to build and test their integrations:\nthe docs our language SDKs, which we call the CLibs (Client Libraries) the actual API :) Over time, we realized keeping all three of these developer-facing surface areas updated and synchronized can be a challenge as our API evolved. Ideally, we wanted one source of truth for our API in order to enforce a consistent experience for external developers, which is why we decided to use an OpenAPI schema as a point of reference to generate the docs, the client libraries, and part of our API.\nWe learned some valuable lessons along the way that we wanted to document and share so that other teams taking on similar projects could benefit. In this article, I\u0026rsquo;m going to walk through how we decided to use the OpenAPI schema at a company with an existing API that we are continuously iterating on, challenges we encountered, and how we overcame them.\nPhilosophy# When we first started generating our SDKs, the bulk of the issues we ran into initially were around making sure our OpenAPI schema was an accurate representation of our API. However, after we resolved most of these issues, we started running into another class of problems \u0026ndash; issues with the generated output of the libraries. For dealing with these issues, there were a couple of things we could modify to improve the generated output:\nThe actual Plaid API implementation OpenAPI schema: sometimes we could use different methods of representing the API within OpenAPI. Also, some features of the OpenAPI version we used weren\u0026rsquo;t fully implemented by all the code generators \u0026ndash; we would abstain from using these features. The actual generator implementation: The project that we ended up using for code generation is OpenAPI Tool\u0026rsquo;s generator. Each code generator is implemented in Java. We could fork the generator and modify this implementation to fit our needs. Templates: The code generators use mustache templates for each language. While we couldn\u0026rsquo;t completely change the output code by modifying templates, we could easily add helper methods or slightly change patterns. Generator parameters: the generator we used had a long list of parameters you can configure, such as packageName, version, and others. Some of these parameters can drastically affect code output. Pre-processing or post-processing the schema or code. For example, we could use scripts to insert in new files like a README.md or modify import paths with a find-and-replace. We wanted to see how feasible modifying the OpenAPI Tools generator was to fit our purposes. We embarked on a short project to try to match our existing plaid-python library through generation by making sweeping adjustments to the Java implementation. We found that our changes were all pretty brittle as matching the questionable patterns in the old plaid-python library was difficult and arbitrary. For example, some endpoints were ordered by product, so /transactions/get would be client.Transactions.get(...). This requirement was enforced inconsistently at times; for example, /accounts/balance/get\u0026rsquo;s method signature was client.Balance.get. This made it difficult to generate code that fit the existing library perfectly. Matching parameter ordering was also near to impossible without a ton of one-off generator edits.\nFinally, we had a latent desire to not commit Java code at Plaid as we mostly don\u0026rsquo;t use Java internally. This resulted in us ruling out any generator implementation changes. Another added bonus of not modifying the generator is that other developers outside of Plaid can generate a working library without using our forked generator!\nTemplate changes were frustrating in general, as we had to have some idea about the generator implementation to modify them. Luckily, our small project with the generator implementation helped us out when making template changes.\nThis exploration helped us stack rank which changes to try first. We came up with something like this:\ngenerator parameters \u0026gt; OAS \u0026gt; templates \u0026gt; any type of processing on the OAS or output code \u0026gt; the Plaid API Header secrets / POST secrets# Usually APIs have some form of authentication. Plaid\u0026rsquo;s endpoints are a little unique in the following way:\nEvery endpoint is an HTTP POST with a JSON attached. For authenticated endpoints, the JSON requestBody has client_id and secret attached as parameters. While this is a reasonable way to authenticate endpoints, it isn\u0026rsquo;t a pattern that OpenAPI supports out-of-the-box. OpenAPI supports BasicAuth and header keys, as well as some other forms of authentication. In old versions of the OpenAPI schema, we ended up having client_id and secret as required parameters in every requestBody. While this was correct and worked, when we generated the library, it made it so calling any endpoint required you to pass in the authentication again.\nold not generated library\nclient.TransactionsGet(params...) default output of generator\nclient.TransactionsGet(client_id, secret, params...) This would have made using our library pretty frustrating as developers would have to wire their Plaid client_id and secret throughout their application and pass it into every endpoint call.\nAs engineers, we disliked the unnecessary complexity, so we considered two options:\nTry to modify the generator to attach authentication on the right endpoints Modify our API and OAS to match an OpenAPI authentication schema Since we were opposed to modifying the generator, we decided to adopt an OpenAPI authentication schema. We discovered that some routes in the past supported header-based authentication where the client_id and secret were sent in the headers under the keys PLAID-CLIENT-ID and PLAID-SECRET. We decided to adopt this standard. However, we didn\u0026rsquo;t want to cause a breaking change to our API by fully migrating to this new pattern. It was important to us that our old libraries were still compatible with the API! So we devised the following solution for every client-facing route: accept authentication either in the headers OR in the request body.\nWe modified every route to have this new authentication and also marked client_id and secret as optional in the requestBody. This allowed us to have a similar pattern to the old client libraries where authentication is passed in automatically, as OpenAPI supports this type of authentication. The library ended up attaching the authentication in the headers for the correct endpoints. Yay!\nAdditive changes don\u0026rsquo;t break JSON (additionalProperties)\nAt Plaid, we\u0026rsquo;ve always treated additive changes to endpoints as non-breaking. This allows us to rapidly ship new functionality and features without forcing developers through API migrations.\nImagine an endpoint that officially returned named parameters (x, y), but one day, the endpoint starts returning (x, y, z): this is consistent with JSON Schema and is ok. It is also valid according to the OpenAPI specification, which states \u0026ldquo;additionalProperties defaults to true\u0026rdquo; for objects, describing this behavior.\nIn our old client libraries, we generally handled additional parameters returning from the API gracefully and just dropped them. However, most of the generators either assumed additionalProperties was false by default and/or did not work correctly with it set to true:\nThe Python generator assumed additionalProperties was false. Upon receiving a response that had extra parameters, the library crashed on deserialization. This is when we decided to add additionalProperties: true to every response model, as we\u0026rsquo;re ok with over-specifying values in our OpenAPI schema even if they\u0026rsquo;re default. The other libraries either dropped values if additionalProperties wasn\u0026rsquo;t set to true, or they\u0026rsquo;d stick it in a map. The default output of the Java generator was a mess. Adding additionalProperties at all to any response model caused an inheritance bug where the model extended HashMap but didn\u0026rsquo;t properly implement the interface. The output code didn\u0026rsquo;t compile, and we couldn\u0026rsquo;t really figure out how to fix it through templating. The behavior when not having additionalProperties was just to drop additional values; we were ok with this. We added a pre-processing step to the OpenAPI file to remove all instances of additionalProperties before handing it to the Java generator. This particular issue was a headache. If you run into this issue, make sure to check all your languages\u0026rsquo; outputs carefully. We debugged this by picking an endpoint that was easy to call with minimal setup (one example for the Plaid API is /categories/get). We would set additionalProperties to true, and then remove a known parameter from the response model of the endpoint. We then fired up the generated code and saw what happened when the library received an unexpected response parameter \u0026ndash; if it didn\u0026rsquo;t crash, we were in the clear.\nRequest and response models inconsistently implemented# In OpenAPI, you can either define your request and response\u0026rsquo;s schema inline or use a $ref to point to a named model. In the initial revision of the OpenAPI schema, all of our endpoint schemas were defined inline something like this:\nendpoint: responses: object: ... requestBody: object: ... We hoped that when generating Python, it would just pick an order for the parameters and output something like:\nclient.Endpoint(requiredParams..., optionals...) Nope. Instead, the generator ended up creating anonymous models called something like inline_model_xx. The endpoint would look like this:\nclient.Endpoint(inline_model_xx(requiredParams..., optionals...)) Not ideal. Some generators flat out didn\u0026rsquo;t work correctly with anonymous objects as well (looking at you, Go). We ended up creating named request and response models for every endpoint. The endpoint TransactionsGet has an associated TransactionsGetRequest and TransactionsGetResponse. The generated code ended up using these names we provided.\nendpoint: responses: $ref: \u0026#34;endpointResponse\u0026#34; requestBody: $ref: \u0026#34;endpointRequest\u0026#34; client.Endpoint(endpointRequest(requiredParams..., optionals...)) Misc. things we had to template# There were a couple of small quality-of-life changes that we templated in. Aside from helper functions for dealing with the libraries, we also did slightly bigger changes.\nClient library initialization \u0026ndash; environments# OpenAPI allows you to define a list of servers that your API supports. Plaid supports three environments – sandbox, development, and production – which all have different URLs. We wanted to support these as constants and allow these constants to be easily inputted as one of the initialization arguments. We had template modifications of this form:\n{{#servers}} const {{{description}}} = \u0026#34;{{{url}}}\u0026#34; {{/servers}} // which yields code like const sandbox = \u0026#34;https://sandbox.plaid.com\u0026#34; ... While this is abusing the description field, we controlled that it was set to something reasonable :).\nVersion pinning# Some of our older client libraries (Node, Python) used to support multiple API versions, because they were thin wrappers over HTTP POST where the responses were basically dictionaries. Now that we are generating the libraries and strongly typing the responses, we only support the latest Plaid API version.\nThe way you specify what API version you\u0026rsquo;re using for Plaid is by setting the Plaid-Version header in your requests. So we added in templating to force this value to the latest API version for all libraries.\nConclusion# These were only a couple of the challenges that we ended up dealing with, and we still have many more improvements we could ship. The project shipped successfully to GA for all of our languages the week of 8/16/21. These new libraries are filled with improvements for developers, including but not limited to:\nbetter adherence to the API and docs. some language-specific features, like async support for Node and contexts for Go. consistency between languages for method names. It was really cool to slowly make these libraries something we\u0026rsquo;d be happy to use ourselves from the default generated outputs. Many of the solutions we came up with during the project focused around cutting the verbosity in using our libraries. If you want to vet the quality of your generated libraries, just try using them! Every time you run into an issue once, your developers who use your SDK will probably run into them 100s of times over.\nWe’re happy to document how we dealt with the many challenges along the way, and hope we can help fellow engineers on a similar journey.\n","date":"2021-09-15","id":14,"permalink":"/posts/plaid-adopting-openapi/","summary":"Originally posted on the Plaid Engineering Blog while I was part of Plaid\u0026rsquo;s Developer Experience Team.\nThe developer experience team focuses on building tools and features that make it as easy as possible for developers to explore our APIs and integrate with Plaid. This year, our team adopted an OpenAPI schema (OAS) as a specification for our API. We launched this schema in beta earlier this year.\nOur team is responsible for maintaining three sources of truth for our API that allow developers to build and test their integrations:\n","tags":["tech"],"title":"Adopting the OpenAPI schema to generate Plaid's SDKs"},{"content":"Originally posted on the Mobile Developers of Berkeley blog\nThis article is going to be a quick intro to the basics of writing modern JavaScript all the time, rather than being dependent on what environment is supported by a given browser.\nIntro# First, what is ES6? ECMAScript 6 is the sixth standardized version of JavaScript, which is ultimately a specification of language features. ES6 added a ton of really great features that drastically improved the ability to construct larger-scale programs with JavaScript (like constants and block scoping!). It’s important to note, as ES6 is only a specification, it’s ultimately up to the browsers to provide an implementation for these new features: often, certain browsers lag behind on implementing all these features (i.e. IE).\nSo that kind of sucks! If that was the end of the story, programmers would essentially have to use the newest version that was supported by all “modern” browsers. However, there’s a process called transpiling, which is like compiling, but goes from code source → code source rather than to an executable. Luckily, there’s a really great project called Babel, which is often used to convert from newer versions of ES → a version supported by most browsers. So from a higher level, the programmer writes code in ES6 / what they’re familiar with, the transpiler converts it to some older version of JS that runs everywhere, and then it’s added to the payload for a website / some type of node app.\nBefore we dive into how to set up the workflow, install npm (node package manager) and node as CLI dependencies (you can figure this out 😛)\nLet’s dive into how to set up this workflow…First, create a new directory and initialize with npm:\nmkdir es6-everywhere cd es6-everywhere npm init # press enter a ton to initialize a default package.json mkdir src touch src/index.js Now we have our project set up, and have an entry point where we can write JS code (“src/index.js”). So we already have a basic setup where we can actually run any normal JS that’s supported by our version of node. If you want to try this yourself, try editing “index.js” to this:\nvar x = 2; console.log(x ** 2); and then run this shell command: node src/index.js.\nYou should see 4 logged to STDOUT! However, this isn’t really that exciting as this is normal JS running within NodeJS. Let’s first start by creating an npm script that executes this script using node. Begin by adding this line to package.json under “scripts”; you should already see an entry for the example script “test”:\n\u0026#34;scripts\u0026#34;: { ... \u0026#34;execute\u0026#34;: \u0026#34;node src/index.js\u0026#34; ES6 vs. Vanilla# Ok! We’ve now kind of gotten the basic flow of executing scripts with npm. However, here’s a code snippet that may or may not work depending on your version of Node (and probably won’t work on IE 8 😛).\nconst square = x =\u0026gt; x * x; let value = 11; console.log(value); value = square(value); console.log(value); If I run npm execute, I actually end up getting the correct values printed out to STDOUT. However, I also have node version 12.9.0, and the whole point of this article is to write JS that’s mostly independent of what version we’re using. Also, let’s take a look at the snippet and the “new” features that it’s using by looking at some of the code.\nconst square = x =\u0026gt; x * x There are a couple of things going on here. First, the const keyword is new! It indicates that a given variable is deemed constant, and its value cannot be changed. However, in the case that it’s pointing to an object (like a list), that object can change, but the pointer to it cannot. In general, it’s good practice to use either const or let instead of var in ES6; this is first because of the fact that we’re specifying in the variable should be mutable or not. Also, both of these variable declarations are block-scoped rather than function-scoped (which is in-line with how some other languages handle variable scoping and a lot clearer). Here’s an example of something that works in normal JS but doesn’t work with const + let for good reason:\n{ var x = 2; } console.log(x) versus\n{ const x = 2; } console.log(x) You can try executing both of these, but basically, for the second snippet, the second example should fail. This allows for much cleaner namespacing and decreases clutter (+ makes it clear when we’re shadowing variable names in places like the block in a conditional statement).\nNow, let’s look at the right side of this line (and one of my favorite ES6 features!): x =\u0026gt; x * x. In ES6 terminology, we refer to this as an arrow-function. The two main advantages of using an arrow function are conciseness and this being lexically bound, with the possible drawback of being anonymous (no name!). The latter advantage is a bit harder to explain and is better appreciated when speaking of ES6 classes, but the first point is dope. If you’re familiar with Python, this statement is equivalent to lambda x: x * x, which is a simple square function.\nPackaging it up# Alright, let’s get back to our objective: we’re trying to convert this to older JS for compatibility reasons! We’re going to have to add some packages, but don’t worry I’ll walk you through what each one does! Run this command in the “es6-everywhere” folder:\nnpm add @babel/core @babel/preset-env babel-loader webpack webpack-cli --save-dev Let’s talk first about babel. Babel is a type of JavaScript compiler that actually compiles between JavaScript versions (also known as a transpiler, or a source-to-source compiler, as we talked about earlier). It’s pretty much exactly what we’re looking for 🙂. Webpack is a really powerful plugin that is used primarily for bundling together tons of assets (like images, JS files, CSS files) into one website with usually one big JS file imported into one HTML file with the assets baked in. We’re going to be using webpack in order to get Babel to run on our code, as that flow will be more similar to how things would be done in production.\nWhen adding new plugins, we’re going to have to configure them. First, let’s start with Babel’s options. Create a new file in “es6-everywhere” called “.babelrc”, and put this in it:\n{ \u0026#34;presets\u0026#34;: [\u0026#34;@babel/preset-env\u0026#34;] } This tells babel the mode to run in, which accepts ES6 as a language input and has a default output that’s generally supported across the board. We can actually further configure the output, but we’re not going to be going into that; if you’re interested, check out the docs on @babel/preset-env.\nWebpack is a bit more complicated. Create a file called “webpack.config.js” and put this in it:\nconst webpack = require(\u0026#39;webpack\u0026#39;); const path = require(\u0026#39;path\u0026#39;); module.exports = { entry: \u0026#39;./src/index.js\u0026#39;, output: { filename: \u0026#39;index.js\u0026#39;, path: path.join(__dirname, \u0026#39;dist\u0026#39;), devtoolModuleFilenameTemplate : \u0026#39;[absolute-resource-path]\u0026#39;, devtoolFallbackModuleFilenameTemplate: \u0026#39;[absolute-resource-path]?[hash]\u0026#39; }, module: { rules: [ { test: /\\.js$/, exclude: /node_modules/, use: { loader: \u0026#34;babel-loader\u0026#34; } } ], }, target: \u0026#34;node\u0026#34; } From a higher level perspective, this tells webpack a couple of things. First, our entry point (the highest level of code) is put in “src/index.js”. Also, we’re going to be outputting to “dist/index.js”. The other interesting thing is that we’re ignoring files inside of the “node_modules” folder; if we didn’t do this, webpack would end up compiling all of the files of the plugins that we add with babel! While we do want the code bundled in in some cases, running the transpiler on it is not what we’re trying to do. Lastly, we indicate that we should be using babel on the files that we’re considering by using the “babel-loader”.\nThis should be all the config we need! Let’s add another npm script to “package.json” in order to actually test our config. Add this under the “scripts” section:\n\u0026#34;yeet\u0026#34;: \u0026#34;webpack --mode development \u0026amp;\u0026amp; cat dist/index.js\u0026#34; This script runs webpack on the file that we specified in the config, and then prints out the output file “dist/index.js” to shell. If you now run npm run yeet | tail you should see an output something like this:\nnpm run yeet | tail !*** ./src/index.js ***! \\**********************/ /*! no static exports found */ /***/ (function(module, exports) { eval(\u0026#34;var square = function square(x) {\\n return x * x;\\n};\\n\\nvar value = 11;\\nconsole.log(value);\\nvalue = square(value);\\nconsole.log(value);\\n\\n//# sourceURL=Users/ajay/programming/es6-everywhere/src/index.js\u0026#34;); /***/ }) /******/ }); We’re done! As you can see, the code has been transformed into something different (for example, our const keywords have been replaced with var keywords, and our arrow function was remade into a normal JS function). If you want to actually run the code, you can modify the yeet script to run node dist/index.js instead of printing it to the terminal, but I’ll leave you to figure that out on your own.\nHave fun writing ES6 everywhere!\n","date":"2019-09-28","id":15,"permalink":"/posts/writing-es6-everywhere/","summary":"Originally posted on the Mobile Developers of Berkeley blog\nThis article is going to be a quick intro to the basics of writing modern JavaScript all the time, rather than being dependent on what environment is supported by a given browser.\nIntro# First, what is ES6? ECMAScript 6 is the sixth standardized version of JavaScript, which is ultimately a specification of language features. ES6 added a ton of really great features that drastically improved the ability to construct larger-scale programs with JavaScript (like constants and block scoping!). It’s important to note, as ES6 is only a specification, it’s ultimately up to the browsers to provide an implementation for these new features: often, certain browsers lag behind on implementing all these features (i.e. IE).\n","tags":["tech"],"title":"Writing ES6 Everywhere"},{"content":"Originally posted on Medium.\nFor my first Medium article, we’re going to go into a quick and easy way to speed up your Python code (and pass those pesky HackerRank tests where you’re just a bit short on time!), as well as some of the technical implementation details for the curious.\n__slots__ is an attribute you can add to a Python class when defining it. You define slots with the possible attributes that an instance of an object can possess. Here’s how you use __slots__:\nclass WithSlots: __slots__ = (\u0026#39;x\u0026#39;, \u0026#39;y\u0026#39;) def __init__(self, x, y): self.x, self.y = x, y For instances of this class, you can use self.x and self.y in the same ways as a normal class instance. However, one key difference between this and instancing from a normal class is that you cannot add or remove attributes from this class’ instances. Say the instance was called w: you couldn’t write w.z = 2 without causing an error.\nThe biggest higher-level reasons to use __slots__ are 1) faster attribute getting and setting due to data structure optimization and 2) reduced memory usage for class instances. Some reasons you wouldn’t want to use it is if your class has attributes that change during run-time (dynamic attributes) or if there’s a complicated object inheritance tree.\nTesting# Let’s first do some tests to see when __slots__ is faster, starting with mass instantiation. Using Python’s “timeit” module and this code snippet, we get the following results:\nclass WithoutSlots: def __init__(self, x, y, z): self.x = x self.y = y self.z = z class WithSlots: __slots__ = (\u0026#39;x\u0026#39;, \u0026#39;y\u0026#39;, \u0026#39;z\u0026#39;) def __init__(self, x, y, z): self.x = x self.y = y self.z = z def instance_fn(cls): def instance(): x = cls(1, 2, 3) return instance Without Slots: 0.3909880230203271 With Slots: 0.31494391383603215 (averaged over 100000 iterations) Instantiation is slightly faster with slots in this case. This makes sense, as we’re denying __dict__ creation for new instances of the given object. Dictionaries generally have more overhead than tuples or lists. Let’s try this with a class that has much more attributes associated to an instance! (This example has 26 attributes):\nWithout Slots: 1.5249411426484585 With Slots: 1.52750033326447 (averaged over 100000 iterations) In general, instantiation time is not really improved by using __slots__. Despite not having to create __dict__, there’s other overhead that needs to be done with slots that we’ll go into later, which results in a similar runtime to copying over the dictionary from the actual class.\nThe real speedup comes into play when we start getting and setting values in rapid succession:\ndef get_set_fn(cls): x = cls(list(range(26))) def get_set(): x.y = x.z + 1 x.a = x.b - 1 x.d = x.q + 3 x.i = x.j - 1 x.z = x.y / 2 return get_set That’s over a 20% speed increase! I’m sure if the test was more extensive (and didn’t always access the same attributes, as well as had attributes that were longer than a single character), there could be a more substantial speedup.\nMemory Usage# First, let’s test the differences between how tuples and dictionaries grow in memory. As using __slots__ knows what attributes can exist for a given instance, it can allocate for the descriptors associated with an instance (instead of having to add a __dict__ for each new object). In Python, it’s a bit difficult to profile the exact amount of memory used by an instance of an object: sys.getsizeof only works well for primitives and built-ins. Instead, we’ll be using a function called asizeof in a library called “Pympler.”\n\u0026gt;\u0026gt;\u0026gt; asizeof((\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;d\u0026#39;)) 304 \u0026gt;\u0026gt;\u0026gt; asizeof({\u0026#39;a\u0026#39;: \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;: \u0026#39;d\u0026#39;}) 512 \u0026gt;\u0026gt;\u0026gt; asizeof(tuple(string.ascii_lowercase)) 1712 \u0026gt;\u0026gt;\u0026gt; dictionary {\u0026#39;e\u0026#39;: \u0026#39;f\u0026#39;, \u0026#39;k\u0026#39;: \u0026#39;l\u0026#39;, \u0026#39;c\u0026#39;: \u0026#39;d\u0026#39;, \u0026#39;g\u0026#39;: \u0026#39;h\u0026#39;, \u0026#39;o\u0026#39;: \u0026#39;p\u0026#39;, \u0026#39;i\u0026#39;: \u0026#39;j\u0026#39;, \u0026#39;s\u0026#39;: \u0026#39;t\u0026#39;, \u0026#39;m\u0026#39;: \u0026#39;n\u0026#39;, \u0026#39;q\u0026#39;: \u0026#39;r\u0026#39;, \u0026#39;a\u0026#39;: \u0026#39;b\u0026#39;, \u0026#39;y\u0026#39;: \u0026#39;z\u0026#39;, \u0026#39;w\u0026#39;: \u0026#39;x\u0026#39;, \u0026#39;u\u0026#39;: \u0026#39;v\u0026#39;} \u0026gt;\u0026gt;\u0026gt; asizeof(dictionary) 2320 We’ve elided an implementation detail for the __slots__ example here: instead of having one tuple for descriptors and one for values, we’ve just put them all in one list. However, we’ll see the size difference isn’t that big compared to the difference between a tuple and a dict:\n\u0026gt;\u0026gt;\u0026gt; asizeof((\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;)) + asizeof((\u0026#39;c\u0026#39;, \u0026#39;d\u0026#39;)) 352 And just for good measure, here’s what happens when we actually run asizeof on our previous example of a slotted class:\n\u0026gt;\u0026gt;\u0026gt; w1 = WithoutSlots(1, 2, 3) \u0026gt;\u0026gt;\u0026gt; asizeof(w1) 416 \u0026gt;\u0026gt;\u0026gt; w2 = WithSlots(4, 5, 6) \u0026gt;\u0026gt;\u0026gt; asizeof(w2) 160 CPython Implementation Details# So first, let’s clear some things up about what CPython is. There’s a standard implementation of the language Python and its core is written in C. It’s probably what’s installed on your machine (and what runs) when you type in python3. You can download the source here.\nI was curious to see what actually changed when defining a class with __slots__, and also just wanted an excuse to prod around CPython’s 3.7.1 release. I’ll also indicate what file to check out if you’re following along at the end of each point. Here’s some key things I picked up:\nWhen __slots__ is found in the class being instantiated (it’s part of the classes default __dict__), __dict__ isn’t created for the new instance. However, the dictionary will be instantiated if you add __dict__ to __slots__, which means you can have the best of both worlds if you know what you’re doing. Files: typeobject.c type_new. Instantiating for classes with __slots__ seems like a bit more work than just creating __dict__. Essentially, you iterate through all the values defined in the class’s dictionary entry of __slots__ and have to set aside descriptors for every single entry. Check out type_new in typeobject.c for more info. Files: typeobject.c type_new. The bytecode generated for classes with slots and without is the same. This means that the differences in lookup are under how the opcode LOAD_ATTR is executed. Check out “dis.dis,” a built-in Python bytecode disassembler. As expected, not having __slots__ ends up doing dictionary lookup: if you’re interested in the details, check out PyDict_GetItem. It ends up getting the pointer to the PyObject which holds the value by looking up in a dictionary. However, if you have __slots__, the descriptor is cached (which contains an offset to directly access the PyObjectwithout doing dictionary lookup). In PyMember_GetOne, it uses the descriptor offset to jump directly where the pointer to the object is stored in memory. This will improve cache coherency slightly, as the pointers to objects are stored in 8 byte chunks right next to each other (I’m using a 64-bit version of Python 3.7.1). However, it’s still a PyObject pointer, which means that it could be stored anywhere in memory. Files: ceval.c, object.c, descrobject.c Some GDB Pointers# If you want to dig around CPython like I did, there’s some setup required before you can start stepping through the code to find what functions run. After downloading the source and installing the required packages (I’d check the build instructions for your machine on the official repo), instead of doing just ./configure, run ./configure --with-pydebug. This creates a debug build of Python instead of a normal one, which allows you to attach GDB to the process. Then you run make to create the binary and debug it using GDB by running gdb python.\nAlso, if I wanted to debug my actual Python code, I had two strategies. Either a) create a conditional breakpoint where I wanted to stop in GDB using the current type-\u0026gt;tp_name string (and naming my class something weird), or b) actually writing the if statement into the code and putting the breakpoint within the statement. I ended up using the latter strategy more often, because I found that pasting in a long breakpoint conditional statement into gdb every time I reopened the debugger was pretty annoying (and I ended up memorizing b object.c:869 after enough run-throughs).\nConclusion# Overall, this article was kind of an excuse for me to look into CPython on my own time 🤤. I ended up learning a ton by downloading and building Python on my own and inserting printf statements in random places as well as using gdb. Also, I had heard the higher-level reasons for why to use __slots__ and actually wanted to test the claims for myself in a more empirical way. Hopefully you learned something new while reading! Leave any questions at the bottom and I’ll try to answer them.\nReferences# StackOverflow: Usage of slots?\nData model - Python 3.7.1 Documentation\nGitHub: python/cpython\n","date":"2018-11-09","id":16,"permalink":"/posts/a-quick-dive-into-pythons-slots/","summary":"Originally posted on Medium.\nFor my first Medium article, we’re going to go into a quick and easy way to speed up your Python code (and pass those pesky HackerRank tests where you’re just a bit short on time!), as well as some of the technical implementation details for the curious.\n__slots__ is an attribute you can add to a Python class when defining it. You define slots with the possible attributes that an instance of an object can possess. Here’s how you use __slots__:\n","tags":["tech"],"title":"A Quick Dive Into Python's Slots"}]